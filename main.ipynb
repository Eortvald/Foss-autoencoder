{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## FOSS Deep Learning Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ran\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import autoencoder, classifier, preprocess\n",
    "from autoencoder.CAE_model import *\n",
    "import os\n",
    "\n",
    "abs_dir = os.path.abspath('')\n",
    "\n",
    "full_path = os.path.join(abs_dir, 'relative/path/to/file/you/want')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('ran')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Preproccesing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Autoencoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_loader = 2\n",
    "test_loader = 2\n",
    "b_size = 4\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# dimension of the hidden layers\n",
    "layer_channels = [8, 16, 32]\n",
    "z_dim = 30"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3 X 32 X 32']\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nTENSOR = torch.rand(128,9,9)\\nbox = torch.tensor(data)\\nprint(TENSOR, box.shape,4*\"\\n\")\\nflad = torch.flatten(TENSOR)\\nprint(\\'New shape: \\n\\',flad.shape)\\n'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conv2D_out_dim(chan, in_dim, kernel, stride, padding, mode = 'Normal'):\n",
    "\n",
    "    if mode == 'Normal':\n",
    "        out_dim = ((in_dim + 2 * padding - 1 * (kernel-1))/stride)+1\n",
    "    #out_dimW = in_dimH if in_dimW is None else in_dimH\n",
    "    else:\n",
    "        out_dim = (in_dim - 1) * stride - 2 * padding + (kernel - 1) + 1\n",
    "        \n",
    "    return [f'{chan} X {out_dim} X {out_dim}']\n",
    "\n",
    "print(conv2D_out_dim(chan = 3,\n",
    "                     in_dim= 17,\n",
    "                     kernel= 2,\n",
    "                     stride= 2,\n",
    "                     padding=1,\n",
    "                     mode = 'Transpose'))\n",
    "\n",
    "#prediction = SimpleVAE(data)\n",
    "#print('Autoencoder are awesome')\n",
    "data = [[[11,22],\n",
    "         [33,44]],\n",
    "        [[55,66],\n",
    "         [77,88]],\n",
    "        [[99,10],\n",
    "         [11,12]]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "TENSOR = torch.rand(128,9,9)\n",
    "box = torch.tensor(data)\n",
    "print(TENSOR, box.shape,4*\"\\n\")\n",
    "flad = torch.flatten(TENSOR)\n",
    "print('New shape: \\n',flad.shape)\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Simple ANN\n",
    "###### Classifier taking Feature vectors from autoencoder as input"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.1208436  -0.9813249  -0.8464829   1.9547759   2.1905026   2.3002977\n",
      " -2.0296998   0.29097757 -0.00861986  0.24387845  0.9227132  -1.4989765\n",
      " -1.9169699   2.1367788  -1.947262   -0.17236489  0.7388807  -0.425935\n",
      " -1.7883965  -0.97878337  1.9060142   0.68945706  1.9558183  -0.6699699\n",
      "  0.18815811 -0.4030525  -0.2615194  -0.42899212  1.1993811  -0.09380686]\n"
     ]
    }
   ],
   "source": [
    "X = torch.ones([1, 8,200,89])\n",
    "\n",
    "ENCODER = CAE(z_dim=30)\n",
    "ENCODER.load_state_dict(torch.load('./autoencoder/model_dicts/CAE_10Kmodel.pth', map_location=device))\n",
    "ENCODER.eval()\n",
    "Z2 = ENCODER.encode(X).detach().numpy()[0]\n",
    "print(Z2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}