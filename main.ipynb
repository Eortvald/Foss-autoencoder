{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## FOSS Deep Learning Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ran\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import *\n",
    "import autoencoder, classifier, preprocess\n",
    "from autoencoder.CAE_model import *\n",
    "import os\n",
    "\n",
    "abs_dir = os.path.abspath('')\n",
    "\n",
    "full_path = os.path.join(abs_dir, 'relative/path/to/file/you/want')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('ran')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Preproccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = 2\n",
    "test_loader = 2\n",
    "b_size = 4\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# dimension of the hidden layers\n",
    "layer_channels = [8, 16, 32]\n",
    "z_dim = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3 X 32 X 32']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTENSOR = torch.rand(128,9,9)\\nbox = torch.tensor(data)\\nprint(TENSOR, box.shape,4*\"\\n\")\\nflad = torch.flatten(TENSOR)\\nprint(\\'New shape: \\n\\',flad.shape)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conv2D_out_dim(chan, in_dim, kernel, stride, padding, mode = 'Normal'):\n",
    "\n",
    "    if mode == 'Normal':\n",
    "        out_dim = ((in_dim + 2 * padding - 1 * (kernel-1))/stride)+1\n",
    "    #out_dimW = in_dimH if in_dimW is None else in_dimH\n",
    "    else:\n",
    "        out_dim = (in_dim - 1) * stride - 2 * padding + (kernel - 1) + 1\n",
    "        \n",
    "    return [f'{chan} X {out_dim} X {out_dim}']\n",
    "\n",
    "print(conv2D_out_dim(chan = 3,\n",
    "                     in_dim= 17,\n",
    "                     kernel= 2,\n",
    "                     stride= 2,\n",
    "                     padding=1,\n",
    "                     mode = 'Transpose'))\n",
    "\n",
    "#prediction = SimpleVAE(data)\n",
    "#print('Autoencoder are awesome')\n",
    "data = [[[11,22],\n",
    "         [33,44]],\n",
    "        [[55,66],\n",
    "         [77,88]],\n",
    "        [[99,10],\n",
    "         [11,12]]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "TENSOR = torch.rand(128,9,9)\n",
    "box = torch.tensor(data)\n",
    "print(TENSOR, box.shape,4*\"\\n\")\n",
    "flad = torch.flatten(TENSOR)\n",
    "print('New shape: \\n',flad.shape)\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple ANN\n",
    "###### Classifier taking Feature vectors from autoencoder as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1208, -0.9813, -0.8465,  1.9548,  2.1905,  2.3003, -2.0297,  0.2910,\n",
      "         -0.0086,  0.2439,  0.9227, -1.4990, -1.9170,  2.1368, -1.9473, -0.1724,\n",
      "          0.7389, -0.4259, -1.7884, -0.9788,  1.9060,  0.6895,  1.9558, -0.6700,\n",
      "          0.1882, -0.4031, -0.2615, -0.4290,  1.1994, -0.0938]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.ones([1, 8,200,89]).to(device)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "aemodel = CAE(z_dim=30).to(device)\n",
    "aemodel.load_state_dict(torch.load('./autoencoder/model_dicts/CAE_10Kmodel.pth', map_location=device))\n",
    "aemodel.eval()\n",
    "\n",
    "ENCO = lambda img : aemodel.encode(img)\n",
    "print(ENCO(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images loaded: [0/100]  ------  19:16:02\n",
      "Done reading train/ images\n",
      "Beginning permute\n",
      "Finished permute\n",
      "Dimension of X is :torch.Size([100, 8, 200, 89])\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "Beginning Norm transform\n",
      "Norm transform finished\n",
      "Dimension of X is :torch.Size([100, 8, 200, 89])------------\n",
      "tensor([[[-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         ...,\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820]],\n",
      "\n",
      "        [[-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         ...,\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317]],\n",
      "\n",
      "        [[-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         ...,\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         ...,\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622]],\n",
      "\n",
      "        [[-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         ...,\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445]],\n",
      "\n",
      "        [[-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         ...,\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690]]])\n",
      "Images loaded: [0/100]  ------  19:16:04\n",
      "Done reading test/ images\n",
      "Beginning permute\n",
      "Finished permute\n",
      "Dimension of X is :torch.Size([100, 8, 200, 89])\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "Beginning Norm transform\n",
      "Norm transform finished\n",
      "Dimension of X is :torch.Size([100, 8, 200, 89])------------\n",
      "tensor([[[-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         ...,\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820]],\n",
      "\n",
      "        [[-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         ...,\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317]],\n",
      "\n",
      "        [[-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         ...,\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         ...,\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622]],\n",
      "\n",
      "        [[-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         ...,\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445]],\n",
      "\n",
      "        [[-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         ...,\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690]]])\n",
      "Using cuda device\n",
      "\n",
      "\t\t------------------------------Epoch: 1------------------------------\n",
      "Avg train loss: 0.20319463729858397\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.19280703663825988  | Accuray: 3.0\n",
      "\n",
      "\t\t------------------------------Epoch: 2------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss: 0.19688735842704774\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.19160661220550537  | Accuray: 5.0\n",
      "\n",
      "\t\t------------------------------Epoch: 3------------------------------\n",
      "Avg train loss: 0.1907899284362793\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.19050767183303832  | Accuray: 17.0\n",
      "\n",
      "\t\t------------------------------Epoch: 4------------------------------\n",
      "Avg train loss: 0.1848139715194702\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.1895427656173706  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 5------------------------------\n",
      "Avg train loss: 0.17897512912750244\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.18857446193695068  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 6------------------------------\n",
      "Avg train loss: 0.17313505649566652\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.18765941262245178  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 7------------------------------\n",
      "Avg train loss: 0.16682950139045716\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.18670464277267457  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 8------------------------------\n",
      "Avg train loss: 0.15955798387527464\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.18557109594345092  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 9------------------------------\n",
      "Avg train loss: 0.1509866750240326\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.1842023742198944  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 10------------------------------\n",
      "Avg train loss: 0.14000848293304444\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.18240173935890197  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 11------------------------------\n",
      "Avg train loss: 0.12568957209587098\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.18025533676147462  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 12------------------------------\n",
      "Avg train loss: 0.10678788423538207\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.17810619235038758  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 13------------------------------\n",
      "Avg train loss: 0.08338998973369599\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.17720694422721864  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 14------------------------------\n",
      "Avg train loss: 0.05973440140485763\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.17928255438804627  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 15------------------------------\n",
      "Avg train loss: 0.04057996153831482\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.18424739003181456  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 16------------------------------\n",
      "Avg train loss: 0.029004257172346115\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.19056522607803345  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 17------------------------------\n",
      "Avg train loss: 0.022536618784070015\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.19531683802604674  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 18------------------------------\n",
      "Avg train loss: 0.01943014971911907\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.19840017080307007  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 19------------------------------\n",
      "Avg train loss: 0.017581254094839096\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.20000901103019714  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 20------------------------------\n",
      "Avg train loss: 0.01638971410691738\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.20242287158966066  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 21------------------------------\n",
      "Avg train loss: 0.015522378459572793\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.2037845027446747  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 22------------------------------\n",
      "Avg train loss: 0.014916435927152633\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.20475543022155762  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 23------------------------------\n",
      "Avg train loss: 0.014463103283196688\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.20510107398033142  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 24------------------------------\n",
      "Avg train loss: 0.01411333654075861\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.20550111413002015  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 25------------------------------\n",
      "Avg train loss: 0.013810988673940301\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.20511459946632385  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 26------------------------------\n",
      "Avg train loss: 0.013553584795445203\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.20449320912361146  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 27------------------------------\n",
      "Avg train loss: 0.013351823966950178\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.20214796781539918  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 28------------------------------\n",
      "Avg train loss: 0.013095473516732454\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.20086300492286682  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 29------------------------------\n",
      "Avg train loss: 0.012903261110186576\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.20126725792884825  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 30------------------------------\n",
      "Avg train loss: 0.012733714748173952\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.20001595377922057  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 31------------------------------\n",
      "Avg train loss: 0.012557294424623252\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.1985477066040039  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 32------------------------------\n",
      "Avg train loss: 0.012372744036838412\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.19821514010429384  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 33------------------------------\n",
      "Avg train loss: 0.01222190510481596\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.1967120087146759  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 34------------------------------\n",
      "Avg train loss: 0.012054624855518342\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.19661420822143555  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 35------------------------------\n",
      "Avg train loss: 0.011934831524267792\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.19611385464668274  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 36------------------------------\n",
      "Avg train loss: 0.011830014232546092\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.19586287021636964  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 37------------------------------\n",
      "Avg train loss: 0.011735514495521784\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.19456411957740782  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 38------------------------------\n",
      "Avg train loss: 0.011608433052897453\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.19440138816833497  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 39------------------------------\n",
      "Avg train loss: 0.011507868431508542\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.19354281067848206  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 40------------------------------\n",
      "Avg train loss: 0.011421122867614032\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.1937064552307129  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 41------------------------------\n",
      "Avg train loss: 0.011331814033910632\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.19297766089439392  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 42------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg train loss: 0.011240926180034876\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.1931622338294983  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 43------------------------------\n",
      "Avg train loss: 0.011169575615786015\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.1931442904472351  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 44------------------------------\n",
      "Avg train loss: 0.011102929380722344\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.19197015047073365  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 45------------------------------\n",
      "Avg train loss: 0.011008150530979038\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.19141049385070802  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 46------------------------------\n",
      "Avg train loss: 0.010930471727624536\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.1910658860206604  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 47------------------------------\n",
      "Avg train loss: 0.010863559171557426\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.19124429702758788  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 48------------------------------\n",
      "Avg train loss: 0.01080695384182036\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.1911171054840088  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 49------------------------------\n",
      "Avg train loss: 0.010747518222779036\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.1910054862499237  | Accuray: 24.0\n",
      "\n",
      "\t\t------------------------------Epoch: 50------------------------------\n",
      "Avg train loss: 0.010697289668023587\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.18991087794303893  | Accuray: 24.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from classifier.MLP_Classifier import *\n",
    "hidden_out = [8, 10, 10, 8]\n",
    "ANN_10Kmodel = ANN(30, hidden_out)\n",
    "ANN_10Kmodel = ANN_10Kmodel.to(device)\n",
    "learningrate = 0.001  # Insert LR\n",
    "epochs = 50  # Insert epochs\n",
    "\n",
    "train_log = []\n",
    "test_log = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\n\\t\\t------------------------------Epoch: {epoch + 1}------------------------------')\n",
    "    tr_loss = train_model(traindataloader, ANN_10Kmodel, ENCO)\n",
    "    train_log.append(tr_loss)\n",
    "    \n",
    "    print('\\t\\t\\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<')\n",
    "    te_loss = model_evaluate(testdataloader, ANN_10Kmodel, ENCO)\n",
    "    test_log.append(te_loss)\n",
    "    \n",
    "torch.save(ANN_10Kmodel.state_dict(), 'classifier/model_dicts/ANN_10Kmodel.pth')\n",
    "\n",
    "plt.plot(np.arange(len(train_log)), train_log, label='Train')  # etc.\n",
    "plt.plot(np.arange(len(test_log)), test_log, label='Test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"Train vs Test\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"plots/classifier-plots/ANN_10K_Results-{str(datetime.now())[5:-10].replace(' ', '_').replace(':', '-')}.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
