{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## FOSS Deep Learning Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ran\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import *\n",
    "import autoencoder, classifier, preprocess\n",
    "from autoencoder.CAE_model import *\n",
    "import os\n",
    "\n",
    "abs_dir = os.path.abspath('')\n",
    "\n",
    "full_path = os.path.join(abs_dir, 'relative/path/to/file/you/want')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('ran')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Preproccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = 2\n",
    "test_loader = 2\n",
    "b_size = 4\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# dimension of the hidden layers\n",
    "layer_channels = [8, 16, 32]\n",
    "z_dim = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3 X 32 X 32']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTENSOR = torch.rand(128,9,9)\\nbox = torch.tensor(data)\\nprint(TENSOR, box.shape,4*\"\\n\")\\nflad = torch.flatten(TENSOR)\\nprint(\\'New shape: \\n\\',flad.shape)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def conv2D_out_dim(chan, in_dim, kernel, stride, padding, mode = 'Normal'):\n",
    "\n",
    "    if mode == 'Normal':\n",
    "        out_dim = ((in_dim + 2 * padding - 1 * (kernel-1))/stride)+1\n",
    "    #out_dimW = in_dimH if in_dimW is None else in_dimH\n",
    "    else:\n",
    "        out_dim = (in_dim - 1) * stride - 2 * padding + (kernel - 1) + 1\n",
    "        \n",
    "    return [f'{chan} X {out_dim} X {out_dim}']\n",
    "\n",
    "print(conv2D_out_dim(chan = 3,\n",
    "                     in_dim= 17,\n",
    "                     kernel= 2,\n",
    "                     stride= 2,\n",
    "                     padding=1,\n",
    "                     mode = 'Transpose'))\n",
    "\n",
    "#prediction = SimpleVAE(data)\n",
    "#print('Autoencoder are awesome')\n",
    "data = [[[11,22],\n",
    "         [33,44]],\n",
    "        [[55,66],\n",
    "         [77,88]],\n",
    "        [[99,10],\n",
    "         [11,12]]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "TENSOR = torch.rand(128,9,9)\n",
    "box = torch.tensor(data)\n",
    "print(TENSOR, box.shape,4*\"\\n\")\n",
    "flad = torch.flatten(TENSOR)\n",
    "print('New shape: \\n',flad.shape)\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple ANN\n",
    "###### Classifier taking Feature vectors from autoencoder as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1208, -0.9813, -0.8465,  1.9548,  2.1905,  2.3003, -2.0297,  0.2910,\n",
      "         -0.0086,  0.2439,  0.9227, -1.4990, -1.9170,  2.1368, -1.9473, -0.1724,\n",
      "          0.7389, -0.4259, -1.7884, -0.9788,  1.9060,  0.6895,  1.9558, -0.6700,\n",
      "          0.1882, -0.4031, -0.2615, -0.4290,  1.1994, -0.0938]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.ones([1, 8,200,89]).to(device)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "aemodel = CAE(z_dim=30).to(device)\n",
    "aemodel.load_state_dict(torch.load('./autoencoder/model_dicts/CAE_10Kmodel.pth', map_location=device))\n",
    "aemodel.eval()\n",
    "\n",
    "ENCO = lambda img : aemodel.encode(img)\n",
    "print(ENCO(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images loaded: [0/8000]  ------  18:53:44\n",
      "Images loaded: [200/8000]  ------  18:53:45\n",
      "Images loaded: [400/8000]  ------  18:53:45\n",
      "Images loaded: [600/8000]  ------  18:53:46\n",
      "Images loaded: [800/8000]  ------  18:53:46\n",
      "Images loaded: [1000/8000]  ------  18:53:47\n",
      "Images loaded: [1200/8000]  ------  18:53:47\n",
      "Images loaded: [1400/8000]  ------  18:53:47\n",
      "Images loaded: [1600/8000]  ------  18:53:48\n",
      "Images loaded: [1800/8000]  ------  18:53:48\n",
      "Images loaded: [2000/8000]  ------  18:53:49\n",
      "Images loaded: [2200/8000]  ------  18:53:49\n",
      "Images loaded: [2400/8000]  ------  18:53:50\n",
      "Images loaded: [2600/8000]  ------  18:53:50\n",
      "Images loaded: [2800/8000]  ------  18:53:51\n",
      "Images loaded: [3000/8000]  ------  18:53:51\n",
      "Images loaded: [3200/8000]  ------  18:53:52\n",
      "Images loaded: [3400/8000]  ------  18:53:52\n",
      "Images loaded: [3600/8000]  ------  18:53:52\n",
      "Images loaded: [3800/8000]  ------  18:53:53\n",
      "Images loaded: [4000/8000]  ------  18:53:53\n",
      "Images loaded: [4200/8000]  ------  18:53:54\n",
      "Images loaded: [4400/8000]  ------  18:53:54\n",
      "Images loaded: [4600/8000]  ------  18:53:55\n",
      "Images loaded: [4800/8000]  ------  18:53:55\n",
      "Images loaded: [5000/8000]  ------  18:53:56\n",
      "Images loaded: [5200/8000]  ------  18:53:56\n",
      "Images loaded: [5400/8000]  ------  18:53:57\n",
      "Images loaded: [5600/8000]  ------  18:53:57\n",
      "Images loaded: [5800/8000]  ------  18:53:58\n",
      "Images loaded: [6000/8000]  ------  18:53:58\n",
      "Images loaded: [6200/8000]  ------  18:53:58\n",
      "Images loaded: [6400/8000]  ------  18:53:59\n",
      "Images loaded: [6600/8000]  ------  18:53:59\n",
      "Images loaded: [6800/8000]  ------  18:54:00\n",
      "Images loaded: [7000/8000]  ------  18:54:00\n",
      "Images loaded: [7200/8000]  ------  18:54:01\n",
      "Images loaded: [7400/8000]  ------  18:54:01\n",
      "Images loaded: [7600/8000]  ------  18:54:02\n",
      "Images loaded: [7800/8000]  ------  18:54:02\n",
      "Done reading train/ images\n",
      "Beginning permute\n",
      "Finished permute\n",
      "Dimension of X is :torch.Size([8000, 8, 200, 89])\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "Beginning Norm transform\n",
      "Norm transform finished\n",
      "Dimension of X is :torch.Size([8000, 8, 200, 89])------------\n",
      "tensor([[[-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         ...,\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820]],\n",
      "\n",
      "        [[-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         ...,\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317]],\n",
      "\n",
      "        [[-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         ...,\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         ...,\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622]],\n",
      "\n",
      "        [[-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         ...,\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445]],\n",
      "\n",
      "        [[-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         ...,\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690]]])\n",
      "Images loaded: [0/2000]  ------  18:56:24\n",
      "Images loaded: [200/2000]  ------  18:56:25\n",
      "Images loaded: [400/2000]  ------  18:56:25\n",
      "Images loaded: [600/2000]  ------  18:56:26\n",
      "Images loaded: [800/2000]  ------  18:56:26\n",
      "Images loaded: [1000/2000]  ------  18:56:27\n",
      "Images loaded: [1200/2000]  ------  18:56:27\n",
      "Images loaded: [1400/2000]  ------  18:56:28\n",
      "Images loaded: [1600/2000]  ------  18:56:28\n",
      "Images loaded: [1800/2000]  ------  18:56:29\n",
      "Done reading test/ images\n",
      "Beginning permute\n",
      "Finished permute\n",
      "Dimension of X is :torch.Size([2000, 8, 200, 89])\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "Beginning Norm transform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm transform finished\n",
      "Dimension of X is :torch.Size([2000, 8, 200, 89])------------\n",
      "tensor([[[-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         ...,\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820],\n",
      "         [-0.4820, -0.4820, -0.4820,  ..., -0.4820, -0.4820, -0.4820]],\n",
      "\n",
      "        [[-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         ...,\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317],\n",
      "         [-0.5317, -0.5317, -0.5317,  ..., -0.5317, -0.5317, -0.5317]],\n",
      "\n",
      "        [[-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         ...,\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315],\n",
      "         [-0.5315, -0.5315, -0.5315,  ..., -0.5315, -0.5315, -0.5315]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         ...,\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622],\n",
      "         [-0.5622, -0.5622, -0.5622,  ..., -0.5622, -0.5622, -0.5622]],\n",
      "\n",
      "        [[-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         ...,\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445],\n",
      "         [-0.5445, -0.5445, -0.5445,  ..., -0.5445, -0.5445, -0.5445]],\n",
      "\n",
      "        [[-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         ...,\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690],\n",
      "         [-0.5690, -0.5690, -0.5690,  ..., -0.5690, -0.5690, -0.5690]]])\n",
      "Using cpu device\n",
      "\n",
      "\t\t------------------------------Epoch: 1------------------------------\n",
      "Avg train loss: 0.00972496473416686\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0012269977852702142  | Accuray: 86.95\n",
      "\n",
      "\t\t------------------------------Epoch: 2------------------------------\n",
      "Avg train loss: 0.004471570750698447\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0009935781210660935  | Accuray: 88.95\n",
      "\n",
      "\t\t------------------------------Epoch: 3------------------------------\n",
      "Avg train loss: 0.0038274920620024206\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0008941624648869038  | Accuray: 89.85\n",
      "\n",
      "\t\t------------------------------Epoch: 4------------------------------\n",
      "Avg train loss: 0.0035188404899090526\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.000838127501308918  | Accuray: 90.0\n",
      "\n",
      "\t\t------------------------------Epoch: 5------------------------------\n",
      "Avg train loss: 0.0033354911729693414\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0008023811522871256  | Accuray: 90.25\n",
      "\n",
      "\t\t------------------------------Epoch: 6------------------------------\n",
      "Avg train loss: 0.003211143862456083\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0007742107138037682  | Accuray: 90.35\n",
      "\n",
      "\t\t------------------------------Epoch: 7------------------------------\n",
      "Avg train loss: 0.0031187301110476256\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.000753606641665101  | Accuray: 90.55\n",
      "\n",
      "\t\t------------------------------Epoch: 8------------------------------\n",
      "Avg train loss: 0.0030494184512645005\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0007398986555635929  | Accuray: 90.6\n",
      "\n",
      "\t\t------------------------------Epoch: 9------------------------------\n",
      "Avg train loss: 0.0029966842345893383\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0007264236528426409  | Accuray: 90.8\n",
      "\n",
      "\t\t------------------------------Epoch: 10------------------------------\n",
      "Avg train loss: 0.0029536607842892406\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.000715951181948185  | Accuray: 91.1\n",
      "\n",
      "\t\t------------------------------Epoch: 11------------------------------\n",
      "Avg train loss: 0.0029202705323696137\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0007071987781673669  | Accuray: 91.1\n",
      "\n",
      "\t\t------------------------------Epoch: 12------------------------------\n",
      "Avg train loss: 0.0028864547638222577\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006982947401702404  | Accuray: 91.0\n",
      "\n",
      "\t\t------------------------------Epoch: 13------------------------------\n",
      "Avg train loss: 0.0028592687807977198\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006934251803904772  | Accuray: 91.15\n",
      "\n",
      "\t\t------------------------------Epoch: 14------------------------------\n",
      "Avg train loss: 0.0028371033621951936\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006876719929277897  | Accuray: 91.15\n",
      "\n",
      "\t\t------------------------------Epoch: 15------------------------------\n",
      "Avg train loss: 0.00281991371139884\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006817337907850743  | Accuray: 91.2\n",
      "\n",
      "\t\t------------------------------Epoch: 16------------------------------\n",
      "Avg train loss: 0.0027970060650259255\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.000677969628944993  | Accuray: 91.2\n",
      "\n",
      "\t\t------------------------------Epoch: 17------------------------------\n",
      "Avg train loss: 0.0027809666227549316\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006728358147665858  | Accuray: 91.3\n",
      "\n",
      "\t\t------------------------------Epoch: 18------------------------------\n",
      "Avg train loss: 0.002768728324212134\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006700504682958127  | Accuray: 90.85\n",
      "\n",
      "\t\t------------------------------Epoch: 19------------------------------\n",
      "Avg train loss: 0.002758132294751704\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006666445536538958  | Accuray: 91.15\n",
      "\n",
      "\t\t------------------------------Epoch: 20------------------------------\n",
      "Avg train loss: 0.0027462355988100173\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006646639816462993  | Accuray: 91.2\n",
      "\n",
      "\t\t------------------------------Epoch: 21------------------------------\n",
      "Avg train loss: 0.0027339617647230627\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006602004319429398  | Accuray: 91.25\n",
      "\n",
      "\t\t------------------------------Epoch: 22------------------------------\n",
      "Avg train loss: 0.0027241122936829923\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006584475049749017  | Accuray: 91.2\n",
      "\n",
      "\t\t------------------------------Epoch: 23------------------------------\n",
      "Avg train loss: 0.0027160580586642028\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.000655300771817565  | Accuray: 91.25\n",
      "\n",
      "\t\t------------------------------Epoch: 24------------------------------\n",
      "Avg train loss: 0.0027060436978936196\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006526417620480061  | Accuray: 91.2\n",
      "\n",
      "\t\t------------------------------Epoch: 25------------------------------\n",
      "Avg train loss: 0.002700306251645088\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006509903008118272  | Accuray: 91.25\n",
      "\n",
      "\t\t------------------------------Epoch: 26------------------------------\n",
      "Avg train loss: 0.0026890749130398036\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. test loss 0.0006498945001512766  | Accuray: 91.15\n",
      "\n",
      "\t\t------------------------------Epoch: 27------------------------------\n",
      "Avg train loss: 0.00268376219086349\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006489262087270618  | Accuray: 91.3\n",
      "\n",
      "\t\t------------------------------Epoch: 28------------------------------\n",
      "Avg train loss: 0.0026818926837295295\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006458117756992578  | Accuray: 91.35\n",
      "\n",
      "\t\t------------------------------Epoch: 29------------------------------\n",
      "Avg train loss: 0.0026717685386538504\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006435773260891437  | Accuray: 91.35\n",
      "\n",
      "\t\t------------------------------Epoch: 30------------------------------\n",
      "Avg train loss: 0.0026655474128201603\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006418319325894118  | Accuray: 91.3\n",
      "\n",
      "\t\t------------------------------Epoch: 31------------------------------\n",
      "Avg train loss: 0.0026618478232994674\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006409347988665104  | Accuray: 91.3\n",
      "\n",
      "\t\t------------------------------Epoch: 32------------------------------\n",
      "Avg train loss: 0.0026546148248016836\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006394627317786217  | Accuray: 91.3\n",
      "\n",
      "\t\t------------------------------Epoch: 33------------------------------\n",
      "Avg train loss: 0.002651394421234727\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006388063486665488  | Accuray: 91.25\n",
      "\n",
      "\t\t------------------------------Epoch: 34------------------------------\n",
      "Avg train loss: 0.002647962963208556\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006374839954078198  | Accuray: 91.3\n",
      "\n",
      "\t\t------------------------------Epoch: 35------------------------------\n",
      "Avg train loss: 0.0026414901204407214\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006366647370159626  | Accuray: 91.4\n",
      "\n",
      "\t\t------------------------------Epoch: 36------------------------------\n",
      "Avg train loss: 0.002635939016472548\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006370500642806291  | Accuray: 91.55\n",
      "\n",
      "\t\t------------------------------Epoch: 37------------------------------\n",
      "Avg train loss: 0.002634403267875314\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006334001291543245  | Accuray: 91.25\n",
      "\n",
      "\t\t------------------------------Epoch: 38------------------------------\n",
      "Avg train loss: 0.002629236257635057\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006325760651379824  | Accuray: 91.4\n",
      "\n",
      "\t\t------------------------------Epoch: 39------------------------------\n",
      "Avg train loss: 0.002623594773001969\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006337438486516475  | Accuray: 91.35\n",
      "\n",
      "\t\t------------------------------Epoch: 40------------------------------\n",
      "Avg train loss: 0.0026210919860750435\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006309439772740007  | Accuray: 91.3\n",
      "\n",
      "\t\t------------------------------Epoch: 41------------------------------\n",
      "Avg train loss: 0.002618101985193789\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006299686711281538  | Accuray: 91.4\n",
      "\n",
      "\t\t------------------------------Epoch: 42------------------------------\n",
      "Avg train loss: 0.002616348210722208\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.000630854593589902  | Accuray: 91.45\n",
      "\n",
      "\t\t------------------------------Epoch: 43------------------------------\n",
      "Avg train loss: 0.002614167744293809\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006288834605365992  | Accuray: 91.35\n",
      "\n",
      "\t\t------------------------------Epoch: 44------------------------------\n",
      "Avg train loss: 0.002607891693711281\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006280577946454287  | Accuray: 91.35\n",
      "\n",
      "\t\t------------------------------Epoch: 45------------------------------\n",
      "Avg train loss: 0.002604913458228111\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006292624231427908  | Accuray: 91.5\n",
      "\n",
      "\t\t------------------------------Epoch: 46------------------------------\n",
      "Avg train loss: 0.0026023444989696147\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006263482067734003  | Accuray: 91.45\n",
      "\n",
      "\t\t------------------------------Epoch: 47------------------------------\n",
      "Avg train loss: 0.0025997543316334487\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006253832783550024  | Accuray: 91.5\n",
      "\n",
      "\t\t------------------------------Epoch: 48------------------------------\n",
      "Avg train loss: 0.00259623674210161\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006253234902396798  | Accuray: 91.55\n",
      "\n",
      "\t\t------------------------------Epoch: 49------------------------------\n",
      "Avg train loss: 0.0025951484823599456\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006264204736799001  | Accuray: 91.65\n",
      "\n",
      "\t\t------------------------------Epoch: 50------------------------------\n",
      "Avg train loss: 0.0025934880385175348\n",
      "\t\t\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<\n",
      "Avg. test loss 0.0006241825371980667  | Accuray: 91.55\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from classifier.MLP_Classifier import *\n",
    "hidden_out = [18]\n",
    "ANN_10Kmodel = ANN(30, hidden_out)\n",
    "ANN_10Kmodel = ANN_10Kmodel.to(device)\n",
    "learningrate = 0.001  # Insert LR\n",
    "epochs = 50  # Insert epochs\n",
    "\n",
    "train_log = []\n",
    "test_log = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'\\n\\t\\t------------------------------Epoch: {epoch + 1}------------------------------')\n",
    "    tr_loss = train_model(traindataloader, ANN_10Kmodel, ENCO)\n",
    "    train_log.append(tr_loss)\n",
    "    \n",
    "    print('\\t\\t\\t>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<')\n",
    "    te_loss = model_evaluate(testdataloader, ANN_10Kmodel, ENCO)\n",
    "    test_log.append(te_loss)\n",
    "    \n",
    "torch.save(ANN_10Kmodel.state_dict(), 'classifier/model_dicts/ANN_10Kmodel.pth')\n",
    "\n",
    "img_name = f\"plots/classifier-plots/ANN_10K_Results-{str(datetime.now())[5:-10].replace(' ', '_').replace(':', '-')}.png\"\n",
    "plt.plot(np.arange(len(train_log)), train_log, label='Train')  # etc.\n",
    "plt.plot(np.arange(len(test_log)), test_log, label='Test')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(\"Train vs Test loss\")\n",
    "plt.legend()\n",
    "plt.savefig(img_name, transparent = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}