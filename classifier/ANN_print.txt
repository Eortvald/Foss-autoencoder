C:\ASB\Projects\EyefossAutoencoder\Fagprojekt-2021\Foss-autoencoder\Foss-venv\Scripts\python.exe C:/ASB/Projects/EyefossAutoencoder/Fagprojekt-2021/Foss-autoencoder/classifier/MLP_Classifier.py
Using cuda:1 device

		------------------------------Epoch: 1------------------------------
100/10000
Avg train loss: 0.01741398003101349
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.021414897298812866  | Accuracy: 0.0
[[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [2.000e+00 0.000e+00 9.998e+03 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]]

		------------------------------Epoch: 2------------------------------
100/10000
Avg train loss: 0.01138435017466545
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.02471259226799011  | Accuracy: 0.0
[[    0.     0.     0.     0.     0.     0.     0.]
 [    0.     0.     0.     0.     0.     0.     0.]
 [    0.     0.     0.     0.     0.     0.     0.]
 [    0.     0. 10000.     0.     0.     0.     0.]
 [    0.     0.     0.     0.     0.     0.     0.]
 [    0.     0.     0.     0.     0.     0.     0.]
 [    0.     0.     0.     0.     0.     0.     0.]]

		------------------------------Epoch: 3------------------------------
100/10000
Avg train loss: 0.009649147349596024
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.023411230611801146  | Accuracy: 0.0
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [ 334.    0. 9666.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 4------------------------------
100/10000
Avg train loss: 0.0089176562666893
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.022146959233283997  | Accuracy: 0.0
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [1753.    0. 8247.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 5------------------------------
100/10000
Avg train loss: 0.008296597868204117
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.021040465354919432  | Accuracy: 0.0
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [3721.    0. 6279.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 6------------------------------
100/10000
Avg train loss: 0.007607737964391709
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.020045815360546112  | Accuracy: 0.0
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [4459.    0. 5541.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 7------------------------------
100/10000
Avg train loss: 0.0068195740252733235
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0184860986828804  | Accuracy: 0.0
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [3965.    0. 6035.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 8------------------------------
100/10000
Avg train loss: 0.006126608324050904
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.016859955036640166  | Accuracy: 0.0
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [1473.    0. 8527.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 9------------------------------
100/10000
Avg train loss: 0.0056098395049571995
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.014911061072349548  | Accuracy: 1.35
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [ 335.    0. 9530.  135.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 10------------------------------
100/10000
Avg train loss: 0.005178343126177788
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.012908468210697174  | Accuracy: 25.569999999999997
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [  14.    0. 7429. 2557.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 11------------------------------
100/10000
Avg train loss: 0.004767431253194809
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.010867837238311768  | Accuracy: 73.85000000000001
[[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [1.000e+00 0.000e+00 2.614e+03 7.385e+03 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]]

		------------------------------Epoch: 12------------------------------
100/10000
Avg train loss: 0.0043911918878555296
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.008591004186868667  | Accuracy: 85.86
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0. 1414. 8586.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 13------------------------------
100/10000
Avg train loss: 0.004032388195395469
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.006400450450181961  | Accuracy: 90.79
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.  921. 9079.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 14------------------------------
100/10000
Avg train loss: 0.0037161976620554925
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.004647323814034462  | Accuracy: 93.73
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.  627. 9373.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 15------------------------------
100/10000
Avg train loss: 0.003454250381886959
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.003664037334918976  | Accuracy: 94.78
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.  522. 9478.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 16------------------------------
100/10000
Avg train loss: 0.003227992556989193
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0030437826052308083  | Accuracy: 95.07
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.  493. 9507.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 17------------------------------
100/10000
Avg train loss: 0.0030363008931279184
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0026711337149143218  | Accuracy: 95.58
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.  442. 9558.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 18------------------------------
100/10000
Avg train loss: 0.0028888845041394233
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0021683536410331728  | Accuracy: 96.3
[[0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]
 [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]
 [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]
 [0.00e+00 1.00e+00 3.69e+02 9.63e+03 0.00e+00 0.00e+00 0.00e+00]
 [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]
 [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]
 [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]]

		------------------------------Epoch: 19------------------------------
100/10000
Avg train loss: 0.002771979630738497
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0020353003457188605  | Accuracy: 96.37
[[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 4.000e+00 3.590e+02 9.637e+03 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]]

		------------------------------Epoch: 20------------------------------
100/10000
Avg train loss: 0.002680877111852169
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0018563749879598618  | Accuracy: 96.49
[[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 6.000e+00 3.450e+02 9.649e+03 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]]

		------------------------------Epoch: 21------------------------------
100/10000
Avg train loss: 0.0026098856166005134
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.001704549901932478  | Accuracy: 96.46000000000001
[[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 7.000e+00 3.470e+02 9.646e+03 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]]

		------------------------------Epoch: 22------------------------------
100/10000
Avg train loss: 0.002551072543114424
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0018318264707922935  | Accuracy: 96.32
[[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 9.000e+00 3.590e+02 9.632e+03 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]]

		------------------------------Epoch: 23------------------------------
100/10000
Avg train loss: 0.002498410937190056
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0015836362637579441  | Accuracy: 96.8
[[0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]
 [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]
 [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]
 [0.00e+00 9.00e+00 3.11e+02 9.68e+03 0.00e+00 0.00e+00 0.00e+00]
 [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]
 [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]
 [0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00 0.00e+00]]

		------------------------------Epoch: 24------------------------------
100/10000
Avg train loss: 0.00245623998567462
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0015839973777532577  | Accuracy: 96.73
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   10.  317. 9673.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 25------------------------------
100/10000
Avg train loss: 0.0024154115952551365
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.001708707857131958  | Accuracy: 96.38
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   13.  349. 9638.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 26------------------------------
100/10000
Avg train loss: 0.0023903314366936685
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0015176316350698472  | Accuracy: 96.71
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   10.  319. 9671.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 27------------------------------
100/10000
Avg train loss: 0.0023579658538103103
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0015618289537727833  | Accuracy: 96.67999999999999
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   11.  321. 9668.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 28------------------------------
100/10000
Avg train loss: 0.0023389197923243048
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0014959007084369659  | Accuracy: 96.76
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   11.  313. 9676.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 29------------------------------
100/10000
Avg train loss: 0.0023049393735826017
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0014617589935660362  | Accuracy: 96.74000000000001
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   11.  315. 9674.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 30------------------------------
100/10000
Avg train loss: 0.002290854175388813
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.001554451034963131  | Accuracy: 96.92
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   19.  289. 9692.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 31------------------------------
100/10000
Avg train loss: 0.0022545784935355186
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0014647681601345538  | Accuracy: 97.03
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   14.  283. 9703.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 32------------------------------
100/10000
Avg train loss: 0.002242532803863287
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0014865700520575046  | Accuracy: 96.89
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   11.  300. 9689.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 33------------------------------
100/10000
Avg train loss: 0.002212984559684992
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0015691268913447856  | Accuracy: 96.77
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   12.  311. 9677.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 34------------------------------
100/10000
Avg train loss: 0.0021940435871481896
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0015393492758274078  | Accuracy: 96.78999999999999
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   12.  309. 9679.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 35------------------------------
100/10000
Avg train loss: 0.0021800727643072606
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0014709839228540659  | Accuracy: 97.09
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   20.  271. 9709.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 36------------------------------
100/10000
Avg train loss: 0.0021651594936847687
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0016358392037451267  | Accuracy: 96.67
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   21.  312. 9667.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 37------------------------------
100/10000
Avg train loss: 0.002139014707505703
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0015371550895273685  | Accuracy: 96.93
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   20.  287. 9693.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 38------------------------------
100/10000
Avg train loss: 0.0021196248099207876
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0014297872960567473  | Accuracy: 97.24000000000001
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   18.  258. 9724.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 39------------------------------
100/10000
Avg train loss: 0.002107124149799347
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0015559052757918835  | Accuracy: 97.00999999999999
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   24.  275. 9701.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 40------------------------------
100/10000
Avg train loss: 0.002089016214758158
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.001544494053721428  | Accuracy: 96.94
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   21.  285. 9694.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 41------------------------------
100/10000
Avg train loss: 0.0020695515766739844
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.001571186389029026  | Accuracy: 96.86
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   21.  293. 9686.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 42------------------------------
100/10000
Avg train loss: 0.002047735019773245
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.001782681107521057  | Accuracy: 96.67
[[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 5.500e+01 2.770e+02 9.667e+03 0.000e+00 1.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]]

		------------------------------Epoch: 43------------------------------
100/10000
Avg train loss: 0.0020443199567496775
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.001782879391312599  | Accuracy: 96.58
[[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 4.600e+01 2.950e+02 9.658e+03 0.000e+00 1.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]]

		------------------------------Epoch: 44------------------------------
100/10000
Avg train loss: 0.002019012988358736
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0016290729075670242  | Accuracy: 96.92
[[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 3.000e+01 2.770e+02 9.692e+03 0.000e+00 1.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]]

		------------------------------Epoch: 45------------------------------
100/10000
Avg train loss: 0.002006472904980183
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0015224497631192207  | Accuracy: 96.98
[[0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 2.100e+01 2.790e+02 9.698e+03 0.000e+00 2.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]
 [0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]]

		------------------------------Epoch: 46------------------------------
100/10000
Avg train loss: 0.0019916446246206762
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0016545132711529732  | Accuracy: 96.74000000000001
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   31.  285. 9674.    0.   10.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 47------------------------------
100/10000
Avg train loss: 0.0019529215604066849
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.00173965462744236  | Accuracy: 96.52
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   42.  284. 9652.    0.   22.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 48------------------------------
100/10000
Avg train loss: 0.0019383504569530487
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0018393377177417277  | Accuracy: 96.36
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   47.  285. 9636.    0.   32.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 49------------------------------
100/10000
Avg train loss: 0.0019227143228054046
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0019322105400264263  | Accuracy: 96.11
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   54.  286. 9611.    0.   49.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]

		------------------------------Epoch: 50------------------------------
100/10000
Avg train loss: 0.001897040383517742
			>>>>>>>>>>>>>>>>TEST RESULTS<<<<<<<<<<<<<<<<<
Avg. test loss 0.0016220013804733753  | Accuracy: 96.7
[[   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.   36.  249. 9670.    0.   45.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]
 [   0.    0.    0.    0.    0.    0.    0.]]
3143.3423611
[0.01741398003101349, 0.01138435017466545, 0.009649147349596024, 0.0089176562666893, 0.008296597868204117, 0.007607737964391709, 0.0068195740252733235, 0.006126608324050904, 0.0056098395049571995, 0.005178343126177788, 0.004767431253194809, 0.0043911918878555296, 0.004032388195395469, 0.0037161976620554925, 0.003454250381886959, 0.003227992556989193, 0.0030363008931279184, 0.0028888845041394233, 0.002771979630738497, 0.002680877111852169, 0.0026098856166005134, 0.002551072543114424, 0.002498410937190056, 0.00245623998567462, 0.0024154115952551365, 0.0023903314366936685, 0.0023579658538103103, 0.0023389197923243048, 0.0023049393735826017, 0.002290854175388813, 0.0022545784935355186, 0.002242532803863287, 0.002212984559684992, 0.0021940435871481896, 0.0021800727643072606, 0.0021651594936847687, 0.002139014707505703, 0.0021196248099207876, 0.002107124149799347, 0.002089016214758158, 0.0020695515766739844, 0.002047735019773245, 0.0020443199567496775, 0.002019012988358736, 0.002006472904980183, 0.0019916446246206762, 0.0019529215604066849, 0.0019383504569530487, 0.0019227143228054046, 0.001897040383517742]
[0.021414897298812866, 0.02471259226799011, 0.023411230611801146, 0.022146959233283997, 0.021040465354919432, 0.020045815360546112, 0.0184860986828804, 0.016859955036640166, 0.014911061072349548, 0.012908468210697174, 0.010867837238311768, 0.008591004186868667, 0.006400450450181961, 0.004647323814034462, 0.003664037334918976, 0.0030437826052308083, 0.0026711337149143218, 0.0021683536410331728, 0.0020353003457188605, 0.0018563749879598618, 0.001704549901932478, 0.0018318264707922935, 0.0015836362637579441, 0.0015839973777532577, 0.001708707857131958, 0.0015176316350698472, 0.0015618289537727833, 0.0014959007084369659, 0.0014617589935660362, 0.001554451034963131, 0.0014647681601345538, 0.0014865700520575046, 0.0015691268913447856, 0.0015393492758274078, 0.0014709839228540659, 0.0016358392037451267, 0.0015371550895273685, 0.0014297872960567473, 0.0015559052757918835, 0.001544494053721428, 0.001571186389029026, 0.001782681107521057, 0.001782879391312599, 0.0016290729075670242, 0.0015224497631192207, 0.0016545132711529732, 0.00173965462744236, 0.0018393377177417277, 0.0019322105400264263, 0.0016220013804733753]
